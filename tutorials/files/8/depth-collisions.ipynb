{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hloubkové senzory - detekce kolizí\n",
    "Cvičení je zaměřené na práci s [hloubkovými mapami](https://en.wikipedia.org/wiki/Depth_map) vzniklých použitím tzv. hloubkových senzorů. V laboratoři jsou k dispozici hloubkové senzory založené na několika principech zisku hloubkových map. Jedná se o kamery typu Kinect, RealSense nebo Time-of-Flight (ToF). \n",
    "\n",
    "Vytvořit stereokameru lze i pomocí dvou obyčejných kamer. Podrobný návod pro zájemce je k dispozici na příklad [zde](https://erget.wordpress.com/2014/02/01/calibrating-a-stereo-camera-with-opencv/).\n",
    "\n",
    "## Typy systémů\n",
    "<table>\n",
    "    <tr>\n",
    "        <th align=\"left\" width=\"16%\"><a href=\"https://en.wikipedia.org/wiki/Kinect\">Microsoft Kinect</a></th>\n",
    "        <th align=\"left\" width=\"16%\"><img src=\"images/kinect.png\" width=\"50%\"/></th>\n",
    "        <th align=\"left\" width=\"16%\"><a href=\"https://en.wikipedia.org/wiki/Intel_RealSense\">Intel RealSense</a></th>\n",
    "        <th align=\"left\" width=\"16%\"><img src=\"images/realsense.png\" width=\"50%\"/></th>\n",
    "        <th align=\"left\" width=\"16%\"><a href=\"https://en.wikipedia.org/wiki/Time-of-flight_camera\">Basler ToF</a></th>\n",
    "        <th align=\"left\" width=\"16%\"><img src=\"images/tof.png\" width=\"50%\"/></th>       \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\" colspan=\"2\">Postaven na principu promítání laserového vzoru a měření jeho deformace infračervenou kamerou.</td>\n",
    "        <td align=\"left\" colspan=\"2\">Využívá stejného principu jako Kinect, pouze má jiný vzor.</td>\n",
    "        <td align=\"left\" colspan=\"2\">Využívá promítání světla z více LED zdrojů a měří čas jeho návratu (odrazu).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\" colspan=\"2\">Je náchylný na měření venku. Denní světlo kazí obraz.</td>\n",
    "        <td align=\"left\" colspan=\"2\">Měl by být vhodný i pro měření venku.</td>\n",
    "        <td align=\"left\" colspan=\"2\">Je náchylný na měření venku. Denní světlo kazí obraz.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=\"left\" colspan=\"2\">Více Kinectů vedle sebe si vzájemně kazí vzory.</td>\n",
    "        <td align=\"left\" colspan=\"2\">Nejnovější a nejmenší senzor na trhu.</td>\n",
    "        <td align=\"left\" colspan=\"2\">Průmyslová konstrukce pro běh 24/7.</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import knihoven a konfigurace\n",
    "Lze využívat i všechny funkce z minulých cvičení. Funkce byly odděleny do samostatného notebooku [svz.ipynb](../svz.ipynb). Pokud klik na odkaz hodí `Error 404`, znamená to, že jupyter notebook nemá přístup k tomuto notebooku. Je třeba spustit jupyter notebook znovu s adresou rootovské složky na adrese minimálně `bi-svz/tutorials/files` (nebo i výše)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%run ../svz.ipynb\n",
    "\n",
    "from ipywidgets import interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import datetime\n",
    "import random\n",
    "from enum import Enum, unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pomocné třídy a funkce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def vizualize_depth_map(depth, threshold_near=0, threshold_far=10, inpaint=False):\n",
    "    # Filtration in depth\n",
    "    depth[depth > threshold_far] = 0\n",
    "    depth[depth < threshold_near] = threshold_near\n",
    "    \n",
    "    # Min-max normalization - v’ = (v-min)/(max-min) * (newmax-newmin) + newmin\n",
    "    depth_scaled = (((depth - depth.min()) / (depth.max() - depth.min() + 0.01)) * 255).astype(np.uint8)\n",
    "\n",
    "    # Inpaint zero values with values from neighbourhood\n",
    "    if inpaint:\n",
    "        _, mask = cv2.threshold(depth_scaled, 1, 255, cv2.THRESH_BINARY_INV)\n",
    "        depth_scaled = cv2.inpaint(depth_scaled, mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "    depth_colormap = cv2.applyColorMap(depth_scaled, cv2.COLORMAP_JET)\n",
    "    # FIXME: This works only on JET palette, because of [128,0,0]\n",
    "    depth_colormap[np.where((depth_colormap==[128,0,0]).all(axis=2))] = [0,0,0]\n",
    "    return depth_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1,
     7,
     274
    ]
   },
   "outputs": [],
   "source": [
    "@unique\n",
    "class ImageType(Enum):\n",
    "    RGB = 1\n",
    "    DEPTH = 2\n",
    "    DEPTH_RAW = 3\n",
    "    COMBI = 4\n",
    "\n",
    "class RealSenseCVViewer:\n",
    "    WIDGET_TYPES = {\n",
    "        'int': widgets.IntSlider,\n",
    "        'float': widgets.FloatSlider,\n",
    "        'bool': widgets.Checkbox,\n",
    "        'int_text': widgets.BoundedIntText,\n",
    "        'float_text': widgets.BoundedFloatText\n",
    "    }\n",
    "\n",
    "    SUPPORTED_CONFIG_NAMES = [\n",
    "        'Gain',\n",
    "        'ExposureTime'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, serial_number, depth_size=(1280, 720), rgb_size=(1280, 720), enable_depth=True, enable_color=True):\n",
    "        # Device config\n",
    "        self._serial_number = serial_number\n",
    "        self._enable_depth = enable_depth\n",
    "        self._enable_color = enable_color\n",
    "        self._depth_frame_width = depth_size[0]\n",
    "        self._depth_frame_height = depth_size[1]\n",
    "        self._rgb_frame_width = rgb_size[0]\n",
    "        self._rgb_frame_height = rgb_size[1]\n",
    "        self._config = None\n",
    "        self.ExposureTime = 800\n",
    "        self.Gain = 39\n",
    "        # Widget config\n",
    "        self._interact_widgets = {}\n",
    "        self._impro_function = None\n",
    "        # Init device config\n",
    "        self.set_camera(serial_number, enable_depth, enable_color)\n",
    "\n",
    "    def set_camera(self, serial_number, enable_depth=True, enable_color=True):\n",
    "        if not self._device_available():\n",
    "            raise ValueError(\"RealSense device {} is not available.\".format(self._serial_number))\n",
    "        self._serial_number = serial_number\n",
    "        self._enable_depth = enable_depth\n",
    "        self._enable_color = enable_color\n",
    "        self._config = rs.config()\n",
    "        self._config.enable_stream(rs.stream.depth, self._depth_frame_width, self._depth_frame_height, rs.format.z16, 30)\n",
    "        self._config.enable_stream(rs.stream.color, self._rgb_frame_width, self._rgb_frame_height, rs.format.bgr8, 30)\n",
    "        self._config.enable_device(self._serial_number)\n",
    "\n",
    "    def set_features(self, features):\n",
    "        new_interact_widgets = {}\n",
    "\n",
    "        for feature in features:\n",
    "            widget_kwargs = {}\n",
    "\n",
    "            if not isinstance(feature, dict):\n",
    "                raise ValueError(\"Feature is not dict type\")\n",
    "            # Extract name for widget\n",
    "            feature_name = feature.get('name')\n",
    "            if feature_name is None:\n",
    "                raise ValueError(\"'name' attribute can't be None\")\n",
    "            # Is this feature implemented?\n",
    "            if feature_name not in self.SUPPORTED_CONFIG_NAMES:\n",
    "                raise ValueError(\"Feature {} is not supported yet.\".format(feature_name))\n",
    "            realsense_feature_default = self._get_default_feature_setting(feature_name)\n",
    "\n",
    "            # realsense_feature = getattr(self._camera, feature_name)\n",
    "            # Extract description for widget\n",
    "            widget_kwargs['description'] = re.sub('([a-z])([A-Z])', r'\\1 \\2', feature_name) + \" :\"\n",
    "            # Extract type\n",
    "            type_name = feature.get('type', 'int')\n",
    "            widget_obj = self.WIDGET_TYPES.get(type_name)\n",
    "            if widget_obj is None:\n",
    "                raise ValueError(\"Widget type name '{}' is not valid.\".format(type_name))\n",
    "            # Extract value\n",
    "            value = feature.get('value', realsense_feature_default['value'])\n",
    "            widget_kwargs['value'] = value\n",
    "\n",
    "            if type_name != 'bool':\n",
    "                step = feature.get('step')\n",
    "                if step is None:\n",
    "                    try:\n",
    "                        step = realsense_feature_default['step']\n",
    "                    except:\n",
    "                        step = 1\n",
    "                widget_kwargs['step'] = step\n",
    "\n",
    "                max_value = feature.get('max', realsense_feature_default['max'])\n",
    "                max_value = (realsense_feature_default['max'], max_value)[max_value <= realsense_feature_default['max']]\n",
    "                widget_kwargs['max'] = max_value\n",
    "\n",
    "                min_value = feature.get('min', realsense_feature_default['min'])\n",
    "                min_value = (realsense_feature_default['min'], min_value)[min_value <= realsense_feature_default['min']]\n",
    "                widget_kwargs['min'] = min_value\n",
    "\n",
    "                layout = feature.get('layout', widgets.Layout(width='99%', height='50px'))\n",
    "                widget_kwargs['layout'] = layout\n",
    "            style = {'description_width': 'initial'}\n",
    "            new_interact_widgets[feature_name] = widget_obj(style=style, **widget_kwargs)\n",
    "\n",
    "        self._interact_widgets = new_interact_widgets\n",
    "\n",
    "    def set_impro_function(self, impro_function, params_dict):\n",
    "        if impro_function is not None and not callable(impro_function):\n",
    "            raise ValueError(\"Object {} is not callable.\".format(impro_function))\n",
    "        self._impro_function = impro_function\n",
    "        self._impro_function_params = params_dict\n",
    "        \n",
    "    def run_interaction_single_shot(self, window_size=None, image_folder='.'):\n",
    "        if not self._device_available():\n",
    "            raise ValueError(\"RealSense device {} is not available.\".format(self._serial_number))\n",
    "        if window_size is not None and not len(window_size) == 2:\n",
    "            raise ValueError(\"Argum\"\n",
    "                             \"ent 'window_size' has to be None or tuple of length 2.\")\n",
    "        interact_manual(self._single_interaction_function_wrap(window_size, image_folder),\n",
    "                        **self._interact_widgets)\n",
    "\n",
    "    def run_interaction_continuous_shot(self, window_size=None, image_folder='.'):\n",
    "        if not self._device_available():\n",
    "            raise ValueError(\"RealSense device {} is not available.\".format(self._serial_number))\n",
    "        if window_size is not None and not len(window_size) == 2:\n",
    "            raise ValueError(\"Argument 'window_size' has to be None or tuple of length 2.\")\n",
    "        self._start_grabbing()\n",
    "        interact_manual(self._continuous_interaction_function_wrap(window_size, image_folder),\n",
    "                        **self._interact_widgets)\n",
    "\n",
    "    def _single_interaction_function_wrap(self, window_size=None, image_folder='.'):\n",
    "        def camera_configuration(**kwargs):\n",
    "            # Refresh settings from GUI\n",
    "            for feature, value in kwargs.items():\n",
    "                setattr(self, feature, value)\n",
    "            # Create simple window if no function is defined\n",
    "            if self._impro_function is None:\n",
    "                cv2.namedWindow('RealSense capture', cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "                if window_size is not None:\n",
    "                    cv2.resizeWindow('RealSense capture', window_size[0], window_size[1])\n",
    "            # Grab one image\n",
    "            self._start_grabbing()\n",
    "            rgb, depth = self._grab_image()\n",
    "            self._stop_grabbing()\n",
    "            if self._impro_function is not None:\n",
    "                rgb, depth = self._impro_function(rgb, depth, **self._impro_function_params)\n",
    "            else:\n",
    "                # Stack both images horizontally\n",
    "                cv2.imshow('RealSense capture', np.hstack(rgb, vizualize_depth_map(depth)))\n",
    "            \n",
    "            # Wait for user's action\n",
    "            while True:\n",
    "                k = cv2.waitKey(1) & 0xFF\n",
    "                if k == ord('s'):\n",
    "                    cv2.imwrite(os.path.join(image_folder, 'RealSenseRgbImage-' + str(\n",
    "                        int(datetime.datetime.now().timestamp())) + '.png'), rgb)\n",
    "                elif k == ord('d'):\n",
    "                    cv2.imwrite(os.path.join(image_folder, 'RealSenseDepthImage-' + str(\n",
    "                    int(datetime.datetime.now().timestamp())) + '.png'), vizualize_depth_map(depth))\n",
    "                elif k == ord('q'):\n",
    "                    break\n",
    "            # Dispose\n",
    "            cv2.destroyAllWindows()\n",
    "            return\n",
    "        return camera_configuration\n",
    "\n",
    "    def _continuous_interaction_function_wrap(self, window_size=None, image_folder='.'):\n",
    "        def camera_configuration(**kwargs):\n",
    "            for feature, value in kwargs.items():\n",
    "                setattr(self, feature, value)\n",
    "            if self._impro_function is None:\n",
    "                cv2.namedWindow('RealSense capture', cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_NORMAL)\n",
    "                if window_size is not None:\n",
    "                    cv2.resizeWindow('RealSense capture', window_size[0], window_size[1])\n",
    "            self._start_grabbing()\n",
    "            \n",
    "            while True:\n",
    "                rgb, depth = self._grab_image()\n",
    "                if self._impro_function is not None:\n",
    "                    rgb, depth = self._impro_function(rgb, depth, **self._impro_function_params)\n",
    "                else:\n",
    "                    cv2.imshow('RealSense capture', np.hstack(rgb, vizualize_depth_map(depth)))\n",
    "                \n",
    "                k = cv2.waitKey(1) & 0xFF\n",
    "                if k == ord('s'):\n",
    "                    cv2.imwrite(os.path.join(image_folder, 'RealSenseRgbImage-' + str(\n",
    "                        int(datetime.datetime.now().timestamp())) + '.png'), rgb)\n",
    "                elif k == ord('d'):\n",
    "                    cv2.imwrite(os.path.join(image_folder, 'RealSenseDepthImage-' + str(\n",
    "                    int(datetime.datetime.now().timestamp())) + '.png'), vizualize_depth_map(depth))\n",
    "                elif k == ord('q'):\n",
    "                    break\n",
    "            cv2.destroyAllWindows()\n",
    "            self._stop_grabbing()\n",
    "            return\n",
    "        return camera_configuration\n",
    "\n",
    "    def save_image(self, filename):\n",
    "        if not self._device_available():\n",
    "            raise ValueError(\"RealSense device {} is not available.\".format(self._serial_number))\n",
    "\n",
    "    def get_image(self, image_type=ImageType.DEPTH):\n",
    "        if not self._device_available():\n",
    "            raise ValueError(\"RealSense device {} is not available.\".format(self._serial_number))\n",
    "        self._start_grabbing()\n",
    "        rgb, depth = self._grab_image()\n",
    "        self._stop_grabbing()\n",
    "        \n",
    "        if image_type is ImageType.DEPTH:\n",
    "            return vizualize_depth_map(depth)\n",
    "        elif image_type is ImageType.RGB:\n",
    "            return rgb\n",
    "        elif image_type is ImageType.COMBI:\n",
    "            return np.hstack(rgb, vizualize_depth_map(depth))\n",
    "        elif image_type is ImageType.DEPTH_RAW:\n",
    "            return depth\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _start_grabbing(self):\n",
    "        self._pipeline = rs.pipeline()\n",
    "        self._profile = self._pipeline.start(self._config)\n",
    "        # Set gain end exposure time\n",
    "        self._profile.get_device().query_sensors()[1].set_option(rs.option.exposure, self.ExposureTime)\n",
    "        self._profile.get_device().query_sensors()[1].set_option(rs.option.gain, self.Gain)\n",
    "        \n",
    "        # Depth scale - units of the values inside a depth frame, i.e how to convert the value to units of 1 meter\n",
    "        depth_sensor = self._profile.get_device().first_depth_sensor()\n",
    "        self._depth_scale = depth_sensor.get_depth_scale()\n",
    "        \n",
    "    def _stop_grabbing(self):\n",
    "        self._pipeline.stop()\n",
    "        \n",
    "    def _grab_image(self):\n",
    "        # Get images\n",
    "        frames = self._pipeline.wait_for_frames(5000)\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        \n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        \n",
    "        # Converts to meters\n",
    "        depth_meters = depth_image * self._depth_scale\n",
    "        \n",
    "        return color_image, depth_meters\n",
    "\n",
    "    def _device_available(self):\n",
    "        context = rs.context()\n",
    "        devices = context.query_devices()\n",
    "        for device in devices:\n",
    "            serial_number = device.get_info(rs.camera_info.serial_number)\n",
    "            if serial_number == self._serial_number:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _get_default_feature_setting(self, feature_name):\n",
    "        if feature_name not in self.SUPPORTED_CONFIG_NAMES:\n",
    "            raise ValueError(\"Feature {} is not supported yet.\".format(feature_name))\n",
    "        if feature_name == 'Gain':\n",
    "            return {'name': 'Gain',\n",
    "                    'description': 'Gain',\n",
    "                    'type': 'float',\n",
    "                    'value': 39.0,\n",
    "                    'min': 0.0,\n",
    "                    'max': 128.0,\n",
    "                    'step': 1.0}\n",
    "        elif feature_name == 'ExposureTime':\n",
    "            return {'name': 'ExposureTime',\n",
    "                    'description': 'Exposure time',\n",
    "                    'type': 'float',\n",
    "                    'value': 800.0,\n",
    "                    'min': 1.0,\n",
    "                    'max': 10000,\n",
    "                    'step': 1.0}\n",
    "\n",
    "features = [\n",
    "    {\n",
    "        \"name\": \"Gain\",\n",
    "        \"description\": \"Gain\",\n",
    "        \"type\": \"float\",\n",
    "        \"value\": 39.0,\n",
    "        \"min\": 0.0,\n",
    "        \"max\": 128.0,\n",
    "        \"step\": 1.0\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ExposureTime\",\n",
    "        \"description\": \"Exposure time\",\n",
    "        \"type\": \"float\",\n",
    "        \"value\": 800.0,\n",
    "        \"min\": 1.0,\n",
    "        \"max\": 10000,\n",
    "        \"step\": 1.0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     41
    ]
   },
   "outputs": [],
   "source": [
    "class EnemyTarget:\n",
    "       \n",
    "    def __init__(self, depth_from, depth_to, img_size):\n",
    "        self.depth_from = depth_from\n",
    "        self.depth_to = depth_to\n",
    "        self.img_size = img_size\n",
    "        self.dead_count = 0\n",
    "        self.coll_toler_depth = 0.05\n",
    "        self.coll_toler_coords = 50\n",
    "        self.is_alive = False\n",
    "        self.coords = None\n",
    "        self.depth = None\n",
    "\n",
    "        self.generate_new()\n",
    "        \n",
    "    def generate_new(self):\n",
    "        self.depth = random.uniform(self.depth_from, self.depth_to)\n",
    "        magic_constant = 2/3\n",
    "        # Pure magic\n",
    "        self.coords = (int(self.img_size[0]/2 + random.uniform(-magic_constant * self.img_size[0]/2 , magic_constant * self.img_size[0]/2)),\n",
    "                         int(self.img_size[1]/2 + random.uniform(-magic_constant* self.img_size[1]/2 , magic_constant * self.img_size[1]/2)))\n",
    "        self.is_alive = True\n",
    "\n",
    "    def check_collision(self, sq_rect, sq_depth):\n",
    "        if sq_rect is None or self.is_alive is False:\n",
    "            return False\n",
    "        sq_x, sq_y = sq_rect[0]\n",
    "        if (abs(sq_x - self.coords[0]) < self.coll_toler_coords \n",
    "                and abs(sq_y - self.coords[1]) < self.coll_toler_coords\n",
    "                and abs(sq_depth - self.depth) < self.coll_toler_depth):\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def collide(self):\n",
    "        self.is_alive = False\n",
    "        self.coords = None\n",
    "        self.depth = None\n",
    "        self.dead_count += 1\n",
    "        print('Získán bod. Celkový počet bodů je: ' + str(self.dead_count))\n",
    "\n",
    "def collision_detect(rgb, depth, **kwargs):\n",
    "    depth = cv2.rotate(depth, cv2.ROTATE_180)\n",
    "    sq_cont, sq_rect, sq_depth = find_square(depth, **kwargs)\n",
    "    target = kwargs['enemy_target']\n",
    "    collides = target.check_collision(sq_rect, sq_depth)\n",
    "    \n",
    "    if collides:\n",
    "        target.collide()\n",
    "        target.generate_new()\n",
    "    \n",
    "    depth[target.coords[1] - 5 : target.coords[1] + 5, target.coords[0] - 5 : target.coords[0] + 5] = target.depth\n",
    "    \n",
    "    sq_target_drawn = cv2.rectangle(np.zeros(depth.shape, dtype=np.uint8), (target.coords[0] - 5, target.coords[1] - 5), \n",
    "                                (target.coords[0] + 5 , target.coords[1] + 5), \n",
    "                                color=(255, 255, 255), thickness=cv2.FILLED)\n",
    "    if sq_cont is not None:\n",
    "        sq_target_drawn = cv2.drawContours(sq_target_drawn, [sq_cont], -1, color=(255, 255, 255), thickness=cv2.FILLED)\n",
    "    \n",
    "    depth_visualized = vizualize_depth_map(depth, kwargs['thresh_near'], kwargs['thresh_far'])\n",
    "    depth_masked = cv2.bitwise_and(depth_visualized, depth_visualized, mask=sq_target_drawn)\n",
    "    show_camera_window(depth_masked)\n",
    "    \n",
    "    return rgb, depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     4
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def area_select(rgb, depth, **kwargs):\n",
    "    show_camera_window(vizualize_depth_map(depth, threshold_far=kwargs['thresh_far'], threshold_near=kwargs['thresh_near']))\n",
    "    return rgb, depth\n",
    "\n",
    "def show_scale(min_val, max_val, color_map='jet'):\n",
    "    fig = plt.figure(figsize=(8, 3))\n",
    "    ax1 = fig.add_axes([0.05, 0.80, 0.9, 0.15])\n",
    "    norm = matplotlib.colors.Normalize(vmin=min_val, vmax=max_val)\n",
    "    cb1 = matplotlib.colorbar.ColorbarBase(ax1, cmap=plt.cm.jet, norm=norm, orientation='horizontal')\n",
    "    cb1.set_label('Depth (meters)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Úkol\n",
    "Cílem cvičení je využít hloubkovou mapu ze senzoru RealSense pro detekci kolizí objektů. K tomu je zapotřebí být schopen počítat reálné rozměry objektů v hloubkových mapách.\n",
    "\n",
    "K výpočtu reálných rozměrů objektů v hloubkové mapě je zapotřebí znát typ senzoru, se kterým se pracuje a jeho zorný úhel jak v horizontálním tak ve vertikálním směru (tzv. FOV). Využívá se geometrie viz následující obrázek (FOV z obrázku **NENÍ** naše hledané). \n",
    "\n",
    "![](https://i.stack.imgur.com/Wf3bu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Najděte správné hodnoty FOV pro váš senzor a doplňte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "FOV_HORIZONTAL_DEGREES =  ###\n",
    "FOV_VERTICAL_DEGREES =  ###\n",
    "\n",
    "def real_measure(w_px, h_px, depth, frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Function for counting the real measures in meters out of pixel values in depth map images.\n",
    "    Source: https://stackoverflow.com/a/45481222/1398955\n",
    "    \n",
    "    @param w_px : int\n",
    "        Width in pixels.\n",
    "    @param h_px : int\n",
    "        Height in pixels.\n",
    "    @param depth : float\n",
    "        Depth value in meters.\n",
    "    @param frame_width : int\n",
    "        Frame width in pixels.\n",
    "    @param frame_height : int\n",
    "        Frame height in pixels.\n",
    "    @return w_m : int\n",
    "        Width in meters.\n",
    "    @return h_m : int\n",
    "        Height in meters.\n",
    "    \"\"\"\n",
    "    fov_horizontal = FOV_HORIZONTAL_DEGREES * np.pi / 180.0\n",
    "    fov_vertical = FOV_VERTICAL_DEGREES * np.pi / 180.0\n",
    "\n",
    "    horizontal_scaling = 2 * np.tan(fov_horizontal / 2.0) / float(frame_width)\n",
    "    vertical_scaling = 2 * np.tan(fov_vertical / 2.0) / float(frame_height)\n",
    "\n",
    "    w_m = w_px * horizontal_scaling * depth\n",
    "    h_m = h_px * vertical_scaling * depth\n",
    "    \n",
    "    return w_m, h_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Doplňte reálné hodnoty nastavení scény\n",
    "Doplňte sériové číslo senzoru, reálné rozměry měřené scény a reálné rozměry snímaného objektu. Seznamte se s barevnou škálou pro určení hloubky objektů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-a89f0bd05dd2>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-a89f0bd05dd2>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    size = (?, ?) ###\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "serial_number = '' ###\n",
    "size = (?, ?) ###\n",
    "\n",
    "# Scene specific measures (meters)\n",
    "thresh_near =  ###\n",
    "thresh_far =  ###\n",
    "thresh_step =  ###\n",
    "\n",
    "# Object specific measures (meters)\n",
    "object_w_m =  ###\n",
    "object_h_m =  ###\n",
    "tolerance =  ###\n",
    "\n",
    "# Shows distance using colors scale bar\n",
    "show_scale(thresh_near, thresh_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Settings dictionary creation - DO NOT modify\n",
    "params_dict = dict()\n",
    "params_dict['image_size'] = size\n",
    "# Depth map thresholds in meters\n",
    "params_dict.update({'thresh_far': thresh_far, 'thresh_near': thresh_near, 'thresh_step': thresh_step})\n",
    "# Real object sizes and measurement tolerance\n",
    "params_dict.update({'object_w_m': object_w_m, 'object_h_m': object_h_m, 'tolerance': tolerance})\n",
    "params_dict['enemy_target'] = EnemyTarget(params_dict['thresh_near'], params_dict['thresh_far'], params_dict['image_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Spusťte snímání a vyzkoušejte si, jak vypadá hloubková mapa\n",
    "Seznamte se s použitím barevné škály v reálném obraze pro určení hloubky objektů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-942c5bb32e55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtof_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marea_select\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'params_dict' is not defined"
     ]
    }
   ],
   "source": [
    "tof_stream(area_select, params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = RealSenseCVViewer(serial_number, depth_size=params_dict['image_size'], rgb_size=params_dict['image_size'])\n",
    "viewer.set_features(features)\n",
    "viewer.set_impro_function(area_select, params_dict)\n",
    "viewer.run_interaction_continuous_shot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Doplňte funkci pro nalezení objektu v obraze\n",
    "Je zapotřebí najít vždy pouze objekt a ne jeho držák nebo jiné falešně pozitivní objekty popř. šum. \n",
    "\n",
    "**Pozn.:** _Znak `\\` uprostřed zdrojového kódu v Pythonu umožňuje rozdělit např. podmínku na více řádků._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def find_square(depth, **kwargs):\n",
    "    thresh_near = kwargs['thresh_near']\n",
    "    thresh_far = kwargs['thresh_far']\n",
    "    thresh_step = kwargs['thresh_step']\n",
    "    object_w_m = kwargs['object_w_m']\n",
    "    object_h_m = kwargs['object_h_m']\n",
    "    tolerance = kwargs['tolerance']\n",
    "    \n",
    "    # For each depth plane\n",
    "    for i in np.arange(thresh_near, thresh_far-thresh_step, thresh_step):\n",
    "        # Clones depth data in one plane to get rid of object holder\n",
    "        depth_clone = np.zeros(depth.shape)\n",
    "        locs = np.where((depth > i) & (depth < i + thresh_step))       \n",
    "        depth_clone[locs[0], locs[1]] = depth[locs[0], locs[1]] * 42 # Just shift by magic constant (basically any number greater than 10 is acceptable)\n",
    "        depth_clone = depth_clone.astype(np.uint8)\n",
    "    \n",
    "        conts, _ = cv2.findContours(depth_clone, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        #FIXME: Sorry for magic constants but it works and speeds up the process ;)\n",
    "        for c in [c for c in conts if cv2.contourArea(c) > 1500 and cv2.contourArea(c) < 15000]:\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            c_x, c_y = rect[0]\n",
    "            w_px, h_px = rect[1]\n",
    "            rect_area = w_px * h_px\n",
    "            square_depth = ... # depth value of found contour\n",
    "            \n",
    "            ### Zvolte správnou funkci se správnými parametry pro měření rozměrů\n",
    "            w_m, h_m =  ###\n",
    "\n",
    "            ### Vytvořte if, ve kterém specifikujete 3 podmínky pro nalezení objektu\n",
    "            # ... velikostí odpovídá skutečnosti\n",
    "            # ... je to čtverec (podle rozměrů)\n",
    "            # ... je to vyplněný čtverec (podle obsahu)\n",
    "            if ... \\\n",
    "                    and ... \\\n",
    "                    and ... :\n",
    "                return c, rect, square_depth\n",
    "         \n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Spusťte snímání a staňte se robotickou rukou\n",
    "Dostaňte kostku do cílového místa a získejte co nejvíc bodů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tof_stream(collision_detect, params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = RealSenseCVViewer(serial_number, depth_size=params_dict['image_size'], rgb_size=params_dict['image_size'])\n",
    "viewer.set_features(features)\n",
    "viewer.set_impro_function(collision_detect, params_dict)\n",
    "viewer.run_interaction_continuous_shot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
