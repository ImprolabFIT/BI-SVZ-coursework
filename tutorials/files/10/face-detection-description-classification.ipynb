{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detekce, popis a klasifikace obličeje z RGB obrazu\n",
    "Druhá část cvičení se zaměří na detekci obličeje pomocí tradičních metod zpracování obrazu a následně na popis a klasifikaci detekovaného obličeje pomocí hlubokých neuronových sítí. Soudobé přístupy oba tyto úkoly typicky spojují do jedné sítě, ale o těch se zmíníme až na konci...\n",
    "\n",
    "## Stažení modelů\n",
    "Do složky `models` s tímto notebookem si stáhněte VGG model, které budeme později používat:\n",
    "\n",
    " https://www.dropbox.com/s/183mgti3tdfmu9d/VGG_FACE_pyTorch_small.t7?dl=1\n",
    "\n",
    "## Detekce obličeje\n",
    "Prvním úkolem je ve vstupním obrazu detekovat umístění obličeje nebo obličejů. Jednak nám to umožní vyfiltrovat nedůležité části obrazu před dalším zpracováním a typicky tak zpracování urychlit a zpřesnit, ale především nám to pomůže při výskytu více obličejů v jednom obrázku. Metody popisu totiž chceme spouštět zaručeně jen na jednom obličeji...\n",
    "\n",
    "Jenže, jak na to? Zkusme si představit jak vypadá typický obličej. Oči a obočí jsou tmavší než tváře, stejně tak jsou tmavší než nos. Jenže modelovat explicitně podobu obličeje je poměrně pracné. Především, když můžeme použít hrubou sílu a nechat si vymodelovat typický obličej ne na úrovni pixelů, ale na úrovni rozdílů intenzit vhodně zvolených oblastí napříč rozlišeními.\n",
    "\n",
    "K tomu je možné použít například Haarovu funkci všemožně naškálovanou a narotovanou jak je podrobněji popsáno v článku Paula Violy a Michaela Jonese: \"Rapid Object Detection using a Boosted Cascade of Simple Features\" a klasifikátor, který bude detekovat ty oblasti obrázku, které obsahují předučenou kombinaci rozdílů intenzit podle vybraných funkcí.\n",
    "\n",
    "<img src=\"images/haar_wavelet.svg\" width=40% style=\"float:left\"> <img src=\"images/haar_application.png\" width=40%>\n",
    "<div style=\"clear:both\"/>\n",
    "\n",
    "Pro učení klasifikátoru je zapotřebí algoritmu dodat velké množství obrázků obličeje (a obrázků, které obličej neobsahují), na kterých proběhne, zjednodušeně řečeno, určení hodnot všech Haarových funkcí a výběr funkcí (a prahů) vhodných pro rozlišení zda obrázek obsahuje nebo neobsahuje obličej. Tím vznikne model, který je při dostatečných schopnostech generalizace možné následně používat pro detekci i neznámých obličejů. Model zde z dat učit nebudeme, použijeme model již natrénovaný pro detekci obličeje dívajícího se přímo do kamery, který je distribuovaný s OpenCV. Pro jistotu jej ale přikládáme přímo do složky s notebookem.\n",
    "\n",
    "### Importy knihoven a modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V Anaconda Prompt nainstalujte PyTorch (**POUZE POKUD tam není**):\n",
    "\n",
    "`conda install pytorch=0.4.1 torchvision cuda90 cudatoolkit=9.0 -c pytorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T13:03:05.787171Z",
     "start_time": "2019-07-17T13:03:05.591797Z"
    }
   },
   "outputs": [],
   "source": [
    "%run ../svz.ipynb\n",
    "face_cascade = cv2.CascadeClassifier('models/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Příprava obrázku a detekce\n",
    "#### 1) Načtěte pomocí knihovny OpenCV obrázek `who_is_this.jpg`, převeďte do RGB pro další zpracování a do odstínů šedi pro detekci Haarovou kaskádou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T13:18:13.901474Z",
     "start_time": "2019-07-17T13:18:12.560158Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image =  ###\n",
    "image_rgb = ...(image) ###\n",
    "image_gray = ...(image) ###\n",
    "\n",
    "plot_images(image_rgb, image_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Detekujte obličeje. Uvedené parametry funkce detectMultiScale specifikují úroveň škálování a citlivost filtru.\n",
    "Pro další práci zachovejte jen první detekovaný obličej, vizualizujte jeho detekci nakreslením obdélníku přes fotografii. **HINT:** *Detekovaný obličej se z pohledu opencv tváří jako Rectangle*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T13:06:08.621555Z",
     "start_time": "2019-07-17T13:06:06.589979Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Detects faces\n",
    "faces = face_cascade.detectMultiScale(image_gray, 1.3, 5)\n",
    "face_rectangle =  ###\n",
    "\n",
    "# Refactors face variable\n",
    "(x,y,w,h) =  ###\n",
    "\n",
    "# Draws rectangle\n",
    "viz = image_rgb.copy()\n",
    "cv2.rectangle(viz, (x,y), (x + w, y + h), (255,0,0), 2)\n",
    "\n",
    "plot_images(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Oblast obličeje ořízněte, zkontrolujte zda je výřez čtvercový, případně upravte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T13:13:06.126965Z",
     "start_time": "2019-07-17T13:13:06.122086Z"
    }
   },
   "outputs": [],
   "source": [
    "cropped = ...(image_rgb, ?, ?, ?, ?) ###\n",
    "resolution = cropped.shape[0:2]\n",
    "\n",
    "ratio =  ###\n",
    "if ratio == 1:\n",
    "    print('Je to čtverec')\n",
    "else:\n",
    "    raise Exception('Není to čtverec, upravte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Popis a klasifikace obličeje\n",
    "Nyní když máme obličej nahrubo označený, zajímalo by nás kdo se za ním skrývá.\n",
    "\n",
    "Opět je pro tyto úlohy používáno velké množství hrubé síly v podobě hlubokých neuronových sítí. Neuronové sítě (dále NN - neural networks) jsou klasifikátory inspirované přírodou, respektive nervovou tkání. Jen pro připomenutí, ta je tvořena jednotlivými (vzájemně velmi podobnými) neurony, které na jedné straně přijímají signál od ostatních neuronů (pomocí různě širokých vstupních kanálů v dendritech, v NN šířkám kanálů říkáme váhy), signál mohou velmi jednoduchými operacemi upravit a při překročení kritické hladiny (prahu) signál transformovaný aktivační funkcí předat dalším neuronům.\n",
    "\n",
    "![](images/neuron.svg)\n",
    "\n",
    "Pro zjednodušení používáme typicky několik omezujících podmínek. Nejčastěji používané sítě jsou dopředné (feed-forward). Neuron tedy může posílat signál pouze směrem vpřed, do další vrstvy; což je druhé zjednodušení. Neurony organizujeme do takzvaných vrstev, kdy všechny neurony v jedné vrstvě mají stejný typ a aktivační funkci (pozor, ne váhy a práh, ty jsou učené nezávisle).\n",
    "\n",
    "Jedinou drobnou komplikací je, že pro zpracování dat s kontextem je vhodné používat konvoluční neuronové sítě (CNN). Konvoluci (1D) snad nemusím připomínat, konvoluční vrstva je pak jen aplikací tohoto principu (\"jedeme\" okénkem po obrázku a vracíme okénkem váženou sumu intenzit pixelů).\n",
    "\n",
    "Pro shrnutí, stačí znát několik základních pojmů:\n",
    "- **vstupní vrstva** - vrstva neuronové sítě, která nemá žádné vstupy a výstupy těchto neuronů jsou nastaveny na hodnoty samotných dat\n",
    "- **výstupní vrstva** - vrstva neuronové sítě, která nemá výstupy ale obsahuje po \"protečení\" dat sítí požadovanou výstupní hodnotu\n",
    "- **plně propojená (fully connected) vrstva** - vrstva, ve které jsou všechny neurony napojené na všechny neurony předchozí vrstvy\n",
    "- **konvoluční (convolutional) vrstva** - vrstva, která počítá konvoluci nad vstupními daty, trénují se tak pro každý výstupní filtr \"jen\" váhy konvolučních jader a jeden práh\n",
    "- **sdružovací (pooling) vrstva** - vrstva redukující dimenzionalitu bez trénovatelných parametrů\n",
    "- **softmax vrstva** - vrstva, které vektor reálných čísel transformuje na distribuci pravděpodobnosti\n",
    "\n",
    "Postup učení umělých neuronových sítí není dobře možné shrnout do několikaminutového tutoriálu, tak si představme, že síť považujeme za velkou černou krabici ze které trčí mnoho set tisíc až milionů potenciometrů. Všechny parametry sítě (včetně \"tvaru\" sítě) jsou laděny tak, aby pro data na vstupu (trénovací množinu, v našem případě intenzity jednotlivých pixelů v jednotlivých kanálech) síť vracela požadovaný výstup (pravděpodobnosti tříd, tedy v našem případě jmen) a pro negativní příklady vracela nuly. Pro představu pomůže velmi dobře stravitelné video od CGP Grey: https://www.youtube.com/watch?v=wvWpdrfoEv0\n",
    "\n",
    "Neuronová síť je jen tak dobrá, jak dobře je vyladěný její model. K tomu jsou potřeba obrovská množství dat. A model pak stejně rozpozná jen to, na co byl natrénován. Takže celou síť od začátku zde trénovat také nebudeme. Ale pokud by Vás zajímalo jaké modely jsou jednoduše dostupné pro PyTorch: http://www.robots.ox.ac.uk/~albanie/pytorch-models.html\n",
    "\n",
    "A když už jsem to nakousl, Torch je jednou z knihoven, která umožňuje uživatelsky přívětivou práci s neuronovými sítěmi (resp. knihovnou THNN), včetně akcelerace na GPU a jejích tenzorových jádrech, což je pro rozumně rychlé (rozuměj: pro větší problémy vůbec možné) trénování neuronových sítí klíčové. Jenže bychom se museli naučit jazyk Lua. Naštěstí má implementované vazby i pro Python v podobě balíčku PyTorch. Jen aby nepřekvapilo, že budeme používat funkci `load_lua`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Načtení knihoven a modelu\n",
    "V našem případě použijeme model uložený ve formátu t7 (pro luatorch), který obsahuje jak informace o tvaru sítě, tak nastavení vah, prahů, aktivačních funkcí, atd. Jen 32. modul trochu opravíme..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.legacy import nn\n",
    "from torch.utils.serialization import load_lua\n",
    "\n",
    "# remove long_size on linux/macos\n",
    "vgg_face = load_lua(\"models/VGG_FACE_pyTorch_small.t7\", long_size=8) \n",
    "vgg_face.modules[31] = nn.View(1, 25088)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Síť VGG16 vypadá takto:\n",
    "![](images/vgg16.png)\n",
    "\n",
    "Námi používaná síť VGG-Face má v poslední, klasifikační vrstvě, 2622 neuronů, jejichž koncové hodnoty odpovídají pravděpodobnosti klasifikace do jmen v souboru `names.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Příprava obličeje a klasifikace + popis\n",
    "#### 1) Nejprve je potřeba oříznutý obličej upravit do podoby, kterou vyžaduje síť.\n",
    "Zmenšete oříznutý obrázek na velikost 224x224 pixelů.\n",
    "Pak **přesuňte** osy tak, aby první osou byl barevný kanál, následně osy y a x (v pořadí běžném pro OpenCV). Ideálně k přesunu osy využijte vhodnou funkci [NumPy](https://www.numpy.org/devdocs/reference/routines.array-manipulation.html). *Hint: swap je špatně :)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = ...(cropped, ...) ### tuple\n",
    "cropped = np....(cropped, ?, ?) ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Od obrázku je nutné odečíst ještě průměrnou hodnotu kanálů použitou při trénování sítě.\n",
    "Tento krok byl použit proto, aby absolutní hodnota vah v síti byla minimální.\n",
    "Vstup pro síť ještě vhodně rozbalíme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = cropped.astype(float)\n",
    "# Magic constants\n",
    "training_mean = [129.1863, 104.7624, 93.5940]\n",
    "\n",
    "for i in range(3):\n",
    "    cropped[i] = cropped[i] - training_mean[i]\n",
    "\n",
    "nn_input = torch.Tensor(cropped).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Výstup zajistíme dopředným spuštěním sítě\n",
    "Najděte pomocí vhodné funkce knihovny NumPy index maximální hodnoty ve výstupním vektoru. Ze souboru `names.txt` zjistěte, které celebritě patří a s jakou pravděpodobností síť třídu přiřadila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_output = vgg_face.forward(nn_input)\n",
    "prediction = np....(nn_output) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open('models/names.txt').readlines()[prediction])\n",
    "nn_output[0, prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speciální význam v síti VGG-Face (i VGG16 obecně) má předposlední vrstva (s indexem 35). Ta obsahuje vektor o délce 4096, který reprezentuje embedding zkoumaného obličeje do prostoru tzv. Eigenfaces - prototypů obličejů. I proto jsou tyto sítě široce používané pro předzpracování obrazových dat do prostoru o výrazně nižší dimenzi. Pro porovnání dvou obličejů je možné použít L2 vzdálenost nad normovanými vektory.\n",
    "\n",
    "## Úkol\n",
    "Nyní máte všechny potřebné ingredience.\n",
    "\n",
    "Z popisu obsaženého v předposlední vrstvě VGG-Face a s využitím binárního lineárního klasifikátoru (např. LinearSVC) z knihovny Scikit-Learn naučte klasifikátor, který od sebe rozpozná Vás od Vašeho souseda.\n",
    "\n",
    "## OpenFace\n",
    "Tento přístup má jistě mnohá úskalí. Pokud se dotyčný nedívá přímo do kamery nebo pokud má výrazně nakloněnou hlavu, detekce ani popis nemusí fungovat správně. Poté je potřeba dělat trochu více magie, kterou nechcete psát stále dokola. A proto vznikla knihovna OpenFace: https://cmusatyalab.github.io/openface/\n",
    "\n",
    "Doporučuji vyzkoušet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
